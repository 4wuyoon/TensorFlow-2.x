{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs2ftVUnLIxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6LrPECiJny-",
        "colab_type": "text"
      },
      "source": [
        "## 뭐뭐있나 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bjk6LtkLF_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "bef6079d-3831-4d9b-ba8f-863a6f590298"
      },
      "source": [
        "# keras\n",
        "#[m for m in dir(keras) if not m.startswith(\"_\")]\n",
        "\n",
        "# 활성화 함수 \n",
        "[m for m in dir(keras.activations) if not m.startswith(\"_\")]\n",
        "\n",
        "# 가중치 초기화 \n",
        "#[name for name in dir(keras.initializers) if not name.startswith(\"_\")]\n",
        "\n",
        "# 스케쥴링\n",
        "#[name for name in dir(keras.optimizers.schedules) if not name.startswith(\"_\")]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['deserialize',\n",
              " 'elu',\n",
              " 'exponential',\n",
              " 'get',\n",
              " 'hard_sigmoid',\n",
              " 'linear',\n",
              " 'relu',\n",
              " 'selu',\n",
              " 'serialize',\n",
              " 'sigmoid',\n",
              " 'softmax',\n",
              " 'softplus',\n",
              " 'softsign',\n",
              " 'swish',\n",
              " 'tanh']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ1zwc3QI7LB",
        "colab_type": "text"
      },
      "source": [
        "## [DNN Model]\n",
        "\n",
        "*   가중치 초기화\n",
        "*   L1, L2 정규화\n",
        "*   맥스노름\n",
        "*   배치정규화\n",
        "*   드롭아웃\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUshy_m06tfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "     \n",
        "    # Flatten\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "     \n",
        "    # Dense\n",
        "    keras.layers.Dense(300, \n",
        "                       activation=\"relu\",\n",
        "                       kernel_initializer=\"he_normal\"), # 가중치 초기화\n",
        "                       kernel_regularizer=keras.regularizers.l1(0.1), # L1, L2 정규화\n",
        "                       kernel_constraint=keras.constraints.max_norm(1.) # 맥스노름\n",
        "                       ) \n",
        "     \n",
        "    # 드롭아웃 + 배치정규화 (활성화함수 앞에서) : 이게 더 좋대\n",
        "    keras.layers.Dense(128, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "\n",
        "    # 드롭아웃 + 배치정규화 (활성화함수 뒤에서)\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "\n",
        "    # 출력층\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcsxTNb7JvL4",
        "colab_type": "text"
      },
      "source": [
        "## [CNN Model]\n",
        "\n",
        "\n",
        "\n",
        "CBAMD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkB18RrF6vKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padding = 'same'이면 제로패딩 사용 O, valid'면 제로패딩 사용 X\n",
        "# pool_size 정수로 하면 높이 너비 둘 다 같게 적용됨. 두 개 정수의 튜플로 하면 높이 너비 각각.\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    \n",
        "    keras.layers.Conv2D(16, 3, strides=2, padding='same', activation='relu', input_shape=(150, 150 ,3)),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "     \n",
        "    #  CBAMD (Conv-BatchNorm-Activation-MaxPool-Dropout)\n",
        "    keras.layers.Conv2D(32, 3, padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Dropout(0.2),\n",
        "     \n",
        "    keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    keras.layers.MaxPooling2D(),\n",
        " \n",
        "    # Flatten + DNN\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J78axIueKKFN",
        "colab_type": "text"
      },
      "source": [
        "## [Compile]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reXVy29k6vOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAagMlPRKc8a",
        "colab_type": "text"
      },
      "source": [
        "### - optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dud3jGXLKdFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SGD / 모멘텀 / 네스테로프 (clipvalue, clipnorm : 그래디언트 클리핑)\n",
        "optimizer=keras.optimizers.SGD(lr=1e-3, clipvalue=1.0, clipnorm=1.0),\n",
        "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
        "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "\n",
        "# AdaGrad\n",
        "optimizer = keras.optimizers.Adagrad(lr=0.001)\n",
        "\n",
        "# RMSProp\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "# Adam / Adamax / Nadam\n",
        "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDFxMvkYPomg",
        "colab_type": "text"
      },
      "source": [
        "## [Early Stopping]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhRyAsmePouY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Early Stopping #####\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights = True)\n",
        "\n",
        "###### Fit할때 콜백함수 넣어주기\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[early_stopping_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHFhiT4bKwmV",
        "colab_type": "text"
      },
      "source": [
        "## [학습률 스케쥴링]\n",
        "\n",
        "\n",
        "1. optimizer의 decay 파라미터 이용\n",
        "\n",
        "2. optimizer의 learning_rate에 schedule을 전달\n",
        "\n",
        "3. 콜백\n",
        "\n",
        "4. 사용자정의 콜백\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsqbka0kLZgq",
        "colab_type": "text"
      },
      "source": [
        "### 1. optimizer의 decay 파라미터 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDUoGk7wLZ2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 거듭제곱 스케쥴링, 에포크마다가 아닌 스텝(배치)마다 업데이트\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(lr=0.01, decay=1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwK2hSRuLtoK",
        "colab_type": "text"
      },
      "source": [
        "### 2. optimizer의 learning_rate에 schedule을 전달"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Zz-vQ5LrRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 지수기반 스케쥴링\n",
        "initial_learning_rate = 0.1\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ")\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=lr_schedule),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAzj0jFhMQKu",
        "colab_type": "text"
      },
      "source": [
        "### 3. 학습률 스케쥴링 - 콜백함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf4Ma06oMQWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " ###### LearningRateScheduler, 에포크마다 학습률 스케쥴링\n",
        " \n",
        "def scheduler(epoch): # 에포크 이용\n",
        "    # 지수기반 스케쥴링\n",
        "    return 0.01 * 0.1**(epoch / 20)\n",
        " \n",
        "def scheduler(epoch, lr): # 에포크, 학습률 이용\n",
        "    # 지수기반 스케쥴링\n",
        "    return lr * 0.1**(1 / 20)\n",
        " \n",
        "def scheduler(epoch):\n",
        "    # 기간별 고정 스케쥴링\n",
        "    if epoch < 5:\n",
        "        return 0.01\n",
        "    elif epoch < 15:\n",
        "        return 0.005\n",
        "    else:\n",
        "        return 0.001\n",
        " \n",
        "lr_scheduler_cb = keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "\n",
        "###### ReduceLROnPlateau \n",
        "\n",
        "# 성능 기반 스케쥴링 : 5번의 연속적인 에포크동안 성능 향상이 일어나지 않으면 학습률에 0.5 곱한다\n",
        "lr_scheduler_cb = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "\n",
        "\n",
        "###### Fit할때 콜백함수 넣어주기\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[lr_scheduler_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-ojZwMtMvsD",
        "colab_type": "text"
      },
      "source": [
        "#### 4. 학습률 스케쥴링 - 사용자 정의 콜백\n",
        "\n",
        "https://www.tensorflow.org/guide/keras/custom_callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHj-ZgI5Mv8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### 스텝마다 지수기반 학습률 스케쥴링\n",
        "K = keras.backend\n",
        "class ExponentialDecay(keras.callbacks.Callback):\n",
        "    def __init__(self, s=40000):\n",
        "        super().__init__()\n",
        "        self.s = s\n",
        " \n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        # 노트: 에포크마다 `batch` 매개변수가 재설정됩니다\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
        "         \n",
        "         \n",
        "n_epochs = 25\n",
        "s = 20 * len(X_train) // 32 # 20 에포크 동안 스텝 횟수 (배치 크기 = 32)\n",
        "exp_decay = ExponentialDecay(s)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[exp_decay])\n",
        "\n",
        "###### 에포크마다 지수기반 학습률 스케쥴링 & 학습률, loss 기록\n",
        "K = keras.backend\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
        "        self.losses.append(logs[\"loss\"])\n",
        "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
        "         \n",
        "expon_lr = ExponentialLearningRate(factor=1.005) # fit 후에 plt.plot(expon_lr.rates, expon_lr.losses)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[expon_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPHsGiSHO9i_",
        "colab_type": "text"
      },
      "source": [
        "## [사용자 정의 콜백]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63aTntVkO-LT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 목표 정확도 달성시 학습 중단\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.998):\n",
        "            print(\"\\nReached 99.8% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        " \n",
        "callbacks = myCallback()\n",
        "\n",
        "# train/val 비율 프린트(오버피팅 감지)\n",
        "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
        "         \n",
        "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
        " \n",
        "\n",
        "# 체크포인트 저장 (학습 도중 컴퓨터가 문제를 일으키는 경우를 대비해서)\n",
        "\n",
        "# early stopping이랑 같이 쓰는거 아니면, fit 끝나고 model = keras.models.load_model(\"my_keras_model.h5\") 로 최상의 모델로 롤백해줘야됨)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hiJfw6HGdWi",
        "colab_type": "text"
      },
      "source": [
        "## [레이블 전처리] one-hot encoding  (scalar -> one-hot vector)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCf1HAkBCVsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# data load : Fashion MNIST\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# preprocess\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "######################################################\n",
        "##### one-hot encoding (scalar -> one-hot vector) ####\n",
        "######################################################\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(set(y_train)))\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(set(y_test)))\n",
        "\n",
        "# modeling\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input_shape 안써줘도 됨.\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy', # sparse_categorical_crossentropy 아님!!!\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fit\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# evaluate\n",
        "test_loss = model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khhx0P9UHMve",
        "colab_type": "text"
      },
      "source": [
        "## [레이블 전처리] one-hot encoding 반대  (one-hot vector -> scalar)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2O0gBunCDy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# data load : Fashion MNIST\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# preprocess\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# one-hot encoding (scalar -> one-hot vector) 데이터가 원레 원핫이었다고 치고..\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(set(y_train)))\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(set(y_test)))\n",
        "\n",
        "#####################################################\n",
        "###### sparse lable (one-hot vector -> scalar) ######\n",
        "######################################################\n",
        "y_train = np.argmax(y_train, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "# modeling\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(), # input_shape 안써줘도 됨.\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', # 그냥 categorical_crossentropy 아님!!\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fit\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# evaluate\n",
        "test_loss = model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE8mdT8qkTgz",
        "colab_type": "text"
      },
      "source": [
        "## [CNN Output Shape 계산기]\n",
        "\n",
        "Output shape 계산식 : [(input_size-Kernel_size + padding*2)/stride] + 1 = output_size\n",
        "\n",
        "\n",
        "\n",
        "input_size, 커널사이즈, 패딩, 스트라이드가 각각 몇 일때 output_shape 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkPUugWtkQoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "def get_output_size(input_size, kernel_size, stride = 1, padding = 'valid'):\n",
        "     \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Conv2D(16, kernel_size, \n",
        "                            strides=stride, \n",
        "                            padding=padding, \n",
        "                            activation='relu', \n",
        "                            input_shape=(input_size, input_size ,3)),\n",
        "        keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    return model.layers[0].output_shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhSek5WRk5tT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4079d93-2783-4a9b-b2bc-b256136308f3"
      },
      "source": [
        "get_output_size(input_size = 32, kernel_size = 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsFWiysyk5xJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dfe4bd49-86ee-4a07-9053-ba167507b7bb"
      },
      "source": [
        "get_output_size(input_size = 32, kernel_size = 3, stride = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E7QBuxOkzhw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "646c5ea2-61cb-4ad9-86fb-9df2881f2ae7"
      },
      "source": [
        "get_output_size(input_size = 32, kernel_size = 3, stride = 2, padding = 'same')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4bcMDkplAK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "39ee8528-dbca-4e95-ed98-18f583470b90"
      },
      "source": [
        "get_output_size(input_size = 32, kernel_size = 3, stride = 2, padding = 'valid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxfp0QlPlKI-",
        "colab_type": "text"
      },
      "source": [
        "## [CNN 상황에 맞는 kernel_size, stride, padding 값 구하기] \n",
        "\n",
        "(input, output사이즈 알고있을때)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdhkMORTkyOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_kernel_size_and_stride(input_size, output_size, kernel_size = 0, stride = 0):\n",
        " \n",
        "    # kernel_size를 모르면\n",
        "    if kernel_size == 0:\n",
        "        ks = range(1, 10)\n",
        "    # kernel_size를 알면\n",
        "    else:\n",
        "        ks = [kernel_size]\n",
        " \n",
        "    # stride를 모르면\n",
        "    if stride == 0:\n",
        "        ss = range(1, 10)\n",
        "    # stride를 알면\n",
        "    else:\n",
        "        ss = [stride]\n",
        " \n",
        "    for k in ks:\n",
        "        for s in ss:\n",
        "            if get_output_size(input_size, k, s, padding = 'valid') == output_size:\n",
        "                print(\"kernel_size : %d, stride : %d, padding = 'valid'\"%(k, s))\n",
        "            if get_output_size(input_size, k, s, padding = 'same') == output_size:\n",
        "                print(\"kernel_size : %d, stride : %d, padding = 'same'\"%(k, s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VJOHnVVkQl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6d80d841-1661-4c0c-c0d9-913af9d99c6d"
      },
      "source": [
        " # input_shape가 32인데 output_shape를 15로 하려면, kernel_size, stride를 몇으로 해야돼?\n",
        " find_kernel_size_and_stride(input_size = 32, output_size = 15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kernel_size : 3, stride : 2, padding = 'valid'\n",
            "kernel_size : 4, stride : 2, padding = 'valid'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0SSIMfFkQjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec0d18c7-9d3f-4789-abbd-9727f6f36743"
      },
      "source": [
        " # input_shape가 32인데 output_shape를 15로 하려고 하는데, kernel_size가 3이래. stride를 몇으로 해야돼?\n",
        "find_kernel_size_and_stride(input_size = 32, output_size = 15, kernel_size = 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kernel_size : 3, stride : 2, padding = 'valid'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XupAVCFQnEjO",
        "colab_type": "text"
      },
      "source": [
        "## [Transfer Learning]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s30Vy209nMT0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 1. 가져와서 그거 그대로 쓰기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KEtl-xikQb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 예전에 만들어서 저장했던 모델\n",
        "my_model.save(\"my_model_A.h5\")\n",
        " \n",
        "# 기존 모델 로딩\n",
        "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
        " \n",
        " \n",
        "\n",
        " \n",
        "# 마지막 층(출력층)은 버리면서 가져오기\n",
        "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
        " \n",
        "# 출력층 새로 붙이기\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        " \n",
        "# 기존 모델의 층 Freezing 시키기\n",
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = False\n",
        " \n",
        "# 컴파일 하기\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "                     metrics=[\"accuracy\"])\n",
        " \n",
        " \n",
        "# 학습시키기\n",
        " \n",
        "# 기존모델 Freezing 풀기\n",
        " \n",
        "# lr 낮춰서 다시 학습시키기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOINnNq-nQoz",
        "colab_type": "text"
      },
      "source": [
        "### 2. 복사해서 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr37_qMSkQY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 예전에 만들어서 저장했던 모델\n",
        "my_model.save(\"my_model_A.h5\")\n",
        " \n",
        "# 기존 모델 로딩\n",
        "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
        "  \n",
        "# 모델 구조 복사해오기\n",
        "model_A_clone = keras.models.clone_model(model_A)\n",
        " \n",
        "# 가중치 복사해오기\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSbuEL67ndb-",
        "colab_type": "text"
      },
      "source": [
        "### 3. inception_v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa3w4gupb2qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        " \n",
        " \n",
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        " \n",
        "# Import the inception model \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        " \n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        " \n",
        " \n",
        "# pre-trained 모델 로드\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        " \n",
        "# pre-trained 가중치 로드                               \n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        " \n",
        "# 전부 Freezing\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        " \n",
        "# pre-trained 모델 output layer 정보\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        " \n",
        "# pre-trained 모델 뒤에 붙일 새로운 네트워크 구성\n",
        "x = keras.layers.Flatten()(last_output)\n",
        "x = keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)                 \n",
        "x = keras.layers.Dense(1, activation='sigmoid')(x)          \n",
        " \n",
        "# 최종 모델 구성 (input, output 지정하기)\n",
        "model = keras.Model( pre_trained_model.input, x)\n",
        " \n",
        "# 컴파일\n",
        "model.compile(optimizer = RMSprop(lr=0.0001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLup5bmPnkEr",
        "colab_type": "text"
      },
      "source": [
        "### 4. Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KywhkyWBnkWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
        " \n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=output)\n",
        " \n",
        "# 훈련 초기에는 사전훈련된 layer의 가중치를 Freezing\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        " \n",
        "# 컴파일\n",
        "optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        " \n",
        "# 학습\n",
        "history = model.fit(train_set,\n",
        "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
        "                    validation_data=valid_set,\n",
        "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
        "                    epochs=5)\n",
        " \n",
        "# 새로 추가한 상위층이 적당히 학습이 되었으니 Freezing 풀고 다시 전체 layer 학습\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        " \n",
        "# 다시 컴파일\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9,\n",
        "                                 nesterov=True, decay=0.001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "# 다시 학습\n",
        "history = model.fit(train_set,\n",
        "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
        "                    validation_data=valid_set,\n",
        "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
        "                    epochs=40)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
